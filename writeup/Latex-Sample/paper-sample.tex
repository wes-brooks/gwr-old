%
% Date: 9/18/2012 Jun
%
%
\documentclass[authoryear,review, 11pt]{elsarticle}

\setlength{\textwidth}{6.5in}
%\setlength{\textheight}{9in}
\setlength{\topmargin}{0in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{booktabs}

\usepackage{color}
\usepackage{bm}

\newtheorem{theorem}{Theorem}

\newcommand\im{\textup{Im\,}}
\newcommand\re{\textup{Re\,}}
\newcommand\prsp{(\Omega, \mathcal F, \mathbf P)}
\newcommand\pr{\mathbf P}
\newcommand{\fej}[1]{\noindent\textsc{#1}}
\newcommand{\FF}{\mathcal{F}}
\newcommand{\E}{\mathbb{E}}

%\journal{XXX}

\begin{document}

\begin{frontmatter}

\title{Fast Estimation and Selection of Autologistic Regression Models via Penalized Pseudo-Likelihood}

\author[rfu]{Rao Fu}
\ead{rfu7@wisc.edu}

\author[athurman]{Andrew L. Thurman}
\ead{athurman@wisc.edu}

%\address[athurman]{Department of Statistics, University of Wisconsin at Madison, Madison, WI 53706}

\author[msteen]{Michelle M. Steen-Adams}
\ead{msteenadams@une.edu}

\author[jzhu]{Jun~Zhu}
\ead{jzhu@stat.wisc.edu}

\address[rfu]{Department of Statistics, University of Wisconsin at Madison, Madison, WI 53706}
\address[athurman]{Department of Statistics, University of Wisconsin at Madison, Madison, WI 53706}
\address[msteen]{Department of Environmental Studies, University of New England, Biddeford, ME 04005}
\address[jzhu]{Department of Statistics and Department of Entomology, University of Wisconsin at Madison, Madison, WI 53706}

\begin{abstract}
XXX
\end{abstract}

\begin{keyword}
XXX
\end{keyword}

\end{frontmatter}

%
% \label{sec:intro}
%
\section{Introduction}
\label{sec:intro}
 
%
% \label{sec:model}
%
\section{Autologistic Regression Models} 
\label{sec:model}

\subsection{Autologistic Regression}
\label{subsec:model:reg}

\subsection{Centered Model}
\label{subsec:model:regCenter}

%
% \label{sec:infer}
%
\section{Estimation and Selection of Autologistic Models}
\label{sec:infer}

\subsection{Maximum Pseudolikelihood}
\label{subsec:infer:pseudo}


\subsection{Variable Selection}
\label{subsec:infer:varsel}


\subsection{Variance Estimation}
\label{subsec:infer:se}

Let $\bm{\mathcal{J}}(\bm{\beta})=\frac{\partial\ell_{{\rm p}}(\bm{\theta})}{\partial\bm{\beta}}\{\frac{\partial\ell_{{\rm p}}(\bm{\theta})}{\partial\bm{\beta}}\}'$. 
%=\sum_{i=1}^n\sum_{j\thicksim i, j=i}\frac{\partial\ell_{{\rm p}i}(\bm{\theta})}{\partial\bm{\beta}}\{\frac{\partial\ell_{{\rm p}j}(\bm{\theta})}{\partial\bm{\beta}}\}'$ and
%$\ell_{{\rm p}i}$ is the log-pseudolikelihood of the $i$th site. 
By arguments similar to \cite{banerjeec04}, the following central limit theory holds for the MPLE $\widehat{\bm{\beta}}_{\rm p}$:
\begin{eqnarray}
\{\bm{\mathcal{J}}(\widehat{\bm{\beta}}_{\rm p})\}^{-1/2} \bm{\mathcal{I}}(\widehat{\bm{\beta}}_{\rm p})\{\widehat{\bm{\beta}}_{\rm p}-\bm{\beta}\} \rightarrow_d \ \mathcal{N}_p(0,\bm{I}_{p+1}).
\label{eqn:CLT}
\end{eqnarray}
Therefore, an estimate of the variance of $\bm{\widehat{\beta}}_{\rm p}$ is
\begin{eqnarray}
\widehat{Var}(\widehat{\bm{\beta}}_{\rm p})\approx\bm{\mathcal{I}}(\widehat{\bm{\beta}}_{\rm p})^{-1}\bm{\mathcal{J}}(\widehat{\bm{\beta}}_{\rm p})\bm{\mathcal{I}}(\widehat{\bm{\beta}}_{\rm p})^{-1}.
\label{eqn:var}
\end{eqnarray}  
For the MPPLE, we replace the MPLE $\widehat{\bm{\beta}}_{\rm p}$ in the variance formula (\ref{eqn:var}) with the vector of non-zero entries of the MPPLE $\widehat{\bm{\beta}}_{\rm pp}$. The operations involved in the variance estimation are of dimension $(p+1)\times(p+1)$ and generally manageable. We will show by a simulation study that these variance estimates perform reasonably well for finite samples.  

In particular under the uncentered model for the 0-1 coding of the response variable, the first-order and second-order derivatives of $\ell_{\rm p}(\bm{\theta})$ with respect to $\bm{\beta}$ are
\begin{eqnarray*}
\bm{\mathcal{I}}(\bm{\beta})&=&\sum_{i=1}^n\bm{x}_i\bm{x}_i'\frac{\exp({\bm{x}_i'\bm{\beta}+\eta\sum_{i'\thicksim i}Z_{i'}})}{\{1+\exp(\bm{x}_i'\bm{\beta}+\eta\sum_{i'\thicksim i}Z_{i'})\}^2}\quad\mbox{and} \\
\bm{\mathcal{J}}(\bm{\beta})&=&\sum_{i=1}^n\sum_{i'\thicksim i, i'=i}\left[\bm{x_i}\left\{Z_i-\frac{\exp(\bm{x}_i'\bm{\beta}+\eta\sum_{i'\thicksim i}Z_{i'})}{1+\exp(\bm{x}_i'\bm{\beta}+\eta\sum_{i'\thicksim i}Z_{i'})}\right\}\right]\\ 
&&\quad\quad\quad\quad\quad\quad\left[\bm{x}_{i'}'\left\{Z_{i'}-\frac{\exp({\bm{x}_{i'}'\bm{\beta}+\eta\sum_{i''\thicksim i'}Z_{i''}})}{1+\exp(\bm{x}_{i'}'\bm{\beta}+\eta\sum_{i''\thicksim i'}Z_{i''})}\right\}\right]'.
\end{eqnarray*}

Under the centered model for the 0-1 coding of the response variable, the first-order and second-order derivatives of $\ell_{\rm p}(\bm{\theta})$ with respect to $\bm{\beta}$ are
\begin{eqnarray*}
\bm{\mathcal{I}}(\bm{\beta})&=&
\sum_{i=1}^n \left[ \bm{x}_i-\eta \sum_{i' \thicksim i} \frac{\exp(\bm{x}_{i'}'\bm{\beta})}{\{1+\exp(\bm{x}_{i'}'\bm{\beta})\}^2}\bm{x}_{i'}\right]\left[ \bm{x}_i-\eta \sum_{i' \thicksim i} \frac{\exp(\bm{x}_{i'}'\bm{\beta})}{\{1+\exp(\bm{x}_{i'}'\bm{\beta})\}^2}\bm{x}_{i'}\right]'\\ 
&&
\frac{\exp({\bm{x}_i'\bm{\beta}+\eta\sum_{i' \thicksim i}(Z_{i'}-\mu_{i'})})} {\{1+\exp(\bm{x}_i'\bm{\beta}+\eta\sum_{i' \thicksim i}(Z_{i'}-\mu_{i'}))\}^2}- \sum_{i=1}^n \sum_{ i' \thicksim i} \eta \left\{Z_i-\frac{\exp({\bm{x}_i'\bm{\beta}+\eta\sum_{i'' \thicksim i}(Z_{i''}-\mu_{i''})})}{1+\exp(\bm{x}_i'\bm{\beta}+\eta\sum_{i'' \thicksim i}(Z_{i''}-\mu_{i''}))}\right\} \\
&& 
\frac{\exp(\bm{x}_{i'}'\bm{\beta})-\{\exp(\bm{x}_{i'}'\bm{\beta})\}^2}{\{1+\exp(\bm{x}_{i'}'\bm{\beta})\}^3}\bm{x}_{i'}\bm{x}_{i'}'
\\
\bm{\mathcal{J}}(\bm{\beta})&=&\sum_{i=1}^n\sum_{i' \thicksim i, i'=i}\left[ \left\{ \bm{x}_i-\eta \sum_{i' \thicksim i} \frac{\exp(\bm{x}_{i'}'\bm{\beta})}{(1+\exp(\bm{x}_{i'}'\bm{\beta}))^2}\bm{x}_{i'} \right\} \left\{Z_i-\frac{\exp({\bm{x}_i'\bm{\beta}+\eta\sum_{i' \thicksim i}(Z_{i'}-\mu_{i'})})}{1+\exp(\bm{x}_i'\bm{\beta}+\eta\sum_{i' \thicksim i}(Z_{i'}-\mu_{i'}))}\right\}\right]\\ 
&&\quad\quad\quad\quad\left[ \left\{ \bm{x}_{i'}-\eta \sum_{i'' \thicksim {i'}} \frac{\exp(\bm{x}_{i''}'\bm{\beta})}{(1+\exp(\bm{x}_{i''}'\bm{\beta}))^2}\bm{x}_{i''} \right\} \left\{Z_{i'}-\frac{\exp({\bm{x}_{i'}'\bm{\beta}+\eta\sum_{i'' \thicksim {i'}}(Z_{i''}-\mu_{i''})})}{1+\exp(\bm{x}_{i'}'\bm{\beta}+\eta\sum_{i'' \thicksim {i'}}(Z_{i''}-\mu_{i''}))}\right\}\right]'.
\end{eqnarray*}

Under the alternative $\pm 1$ coding, the variance estimation can be obtained in analogy to (\ref{eqn:var})
\begin{eqnarray}
\widehat{Var}(\widehat{\tilde{\bm{\beta}}}_{\rm p})\approx\bm{\mathcal{I}}(\widehat{\tilde{\bm{\beta}}}_{\rm p})^{-1}\bm{\mathcal{J}}(\widehat{\tilde{\bm{\beta}}}_{\rm p})\bm{\mathcal{I}}(\widehat{\tilde{\bm{\beta}}}_{\rm p})^{-1}.
\label{eqn:varCenter}
\end{eqnarray}  
Under uncentered model ,the first-order and second-order derivatives of $\ell_{\rm p}(\tilde{\bm{\theta}})$ with respect to $\tilde{\bm{\beta}}$ are
\begin{eqnarray*}
\bm{\mathcal{I}}(\bm{\tilde{\beta}})&=&\sum_{i=1}^n \bm{x}_i\bm{x}_i' \left[1-\left\{\frac{ \sinh({\bm{x}_i'\bm{\tilde{\beta}}+\tilde{\eta}\sum_{i' \thicksim i}\tilde{Z}_{i'}})}{\cosh(\bm{x}_i'\bm{\tilde{\beta}}+\tilde{\eta}\sum_{i' \thicksim i}\tilde{Z}_{i'})}\right\}^2\right]\\
\bm{\mathcal{J}}(\bm{\tilde{\beta}})&=&\sum_{i=1}^n \sum_{i'\thicksim i, i'=i}\left[\bm{x}_i\left\{\tilde{Z}_i-\frac{\sinh({\bm{x}_i'\bm{\tilde{\beta}}+\tilde{\eta}\sum_{i' \thicksim i}\tilde{Z}_{i'}})}{\cosh(\bm{x}_i'\bm{\tilde{\beta}}+\tilde{\eta}\sum_{i' \thicksim i}\tilde{Z}_{i'})}\right\}\right]\\
&&\quad\quad\quad\quad\quad\quad\left[\bm{x}_{i'}\left\{\tilde{Z}_{i'}-\frac{\sinh({\bm{x}_{i'}'\bm{\tilde{\beta}}+\tilde{\eta}\sum_{i'' \thicksim i'}\tilde{Z}_{i''}})}{\cosh(\bm{x}_{i'}'\bm{\tilde{\beta}}+\tilde{\eta}\sum_{i'' \thicksim i'}\tilde{Z}_{i''})}\right\}\right]'.
\end{eqnarray*}

\section{Simulation Study}
\label{sec:simu}

\subsection{Simulation Set-up}

We conducted a simulation study to examine the finite-sample properties of the method developed in Sections~\ref{sec:model}--\ref{sec:infer}.  Consider an $m\times m$ square lattice, where $m=15$ or $30$, corresponding to sample sizes $n=225$ or $900$.  For spatial dependence, the neighborhood structure is of the first order and the autoregression coefficient $\eta$ is either 0.3 or 0.7, corresponding to weaker or stronger spatial dependence. 

Let $\bm{u}_j=(u_{j1},\ldots,u_{jn})'$ denote the $j$th covariate vector such that $\{u_{ji}:i=1,\ldots,n\}$ is a Gaussian random field with mean 0 and an exponential covariance function
\begin{eqnarray}
Cov(u_{ji}, u_{ji'})&=&\sigma^2 \exp(-|i-i'|/ \tau), 
\end{eqnarray}
where we let the variance parameter be $\sigma^2=1$ and the range parameter be $\tau=0.1$.  
To obtain cross-covariate correlation, let $\bm{u}_i=(u_{1i},\ldots, u_{pi})'$ and $\bm{x}_i=\bm{A}\bm{u}_i$ for site $i$, where $\bm{A}\bm{A}'=[\rho^{|j-j'|}]^{p}_{j,j'=1}$ and $\rho=0.4$.

Let $p=10$ be the number of covariates.  The regression coefficients is set to be $\bm{\beta}=(1,\beta_1,1,1,\bm{0}_7')'$, that is, 3 out of 10 coefficients are non-zero and the remaining 7 coefficients are zero.  For the 0-1 coding, we adopt the notion of an average large-scale structure as the average of $\mu_i$ over all sites and covariates \citep{fanl01}.  Let
\begin{eqnarray}
\label{eqn:averlarge1}
\bar{\mu}=\frac{1}{n}\sum_{i=1}^{n}\mu_i=\frac{1}{n}\sum_{i=1}^{n}\frac{\exp({\bm{x}_i'\bm{\beta}})}{1+\exp(\bm{x}_i'\bm{\beta})}
\end{eqnarray}
The large-scale structure is considered to be weak when $\bar{\mu}$ is around 0.5 and strong otherwise. For the $\pm 1$ coding, we define the average large-scale structure analogously as
\begin{eqnarray}
\bar{\tilde{\mu}}=\frac{1}{n}\sum_{i=1}^{n}\tilde{\mu}_i=\frac{1}{n}\sum_{i=1}^{n}\frac{\sinh({\bm{x}_i'\tilde{\bm{\beta}}})}{\cosh(\bm{x}_i'\tilde{\bm{\beta}})}
\label{eqn:averlarge2}
\end{eqnarray}
In this case, the large-scale structure is considered to be weak if $\bar{\tilde{\mu}}$ is close to 0 but strong otherwise.  Here, we let $\beta_1=1$ or 5, which corresponds to a stronger or weaker large-scale structure, respectively.  

\subsection{Simulation Results}
% selection result   

Table~\ref{tab:selstrong} provides the results of variable selection for sample size $n=225$ and $900$ in terms of the average numbers of correctly identified zero-valued and non-zero regression coefficients. The true number of non-zero and zero regression coefficients are 3 and 7, respectively.  

\section{Data Example}
\label{sec:data}

\cite{banerjeec04} did this ... The arguments are like this \citep{banerjeec04}.  Equation (\ref{eqn:var}) implies this...

\section{Conclusions and Discussion}
\label{sec:disc}

\section*{Acknowledgments}

\begin{thebibliography}{00}

\bibitem[Banerjee~\textit{et al.}(2004)]{banerjeec04} Banerjee, S., and Carlin, B.P., and Gelfand, A.E. (2004)  \textit{Hierarchical Modeling and Analysis for Spatial Data}, Chapman and Hall: Boca Raton.

\bibitem[Besag(1972)]{besag72} Besag, J. (1972) Nearest-neighbour systems and the auto-logistic model for binary data. \textit{Journal of the Royal Statistical Society Series B}, \textbf{34}, 75--83.

\bibitem[Diggle and Ribeiro(2007)]{diggler07} Diggle, P.J. and Ribeiro, P.J. (2007) \textit{Model-based Geostatistics}, New York: Springer.

\bibitem[Efron~\textit{et al.}(2004)]{efronh04} Efron, B., Hastie, T., and Johnstone, I. and Tibshirani, R. (2004) Least angle regression (with discussion). \textit{Annals of Statistics}, \textbf{32}, 407--499.

\bibitem[Fan and Li(2001)]{fanl01} Fan, J. and Li, R. (2001) Variable Selection via Nonconcave Penalized Likelihood and its Oracle Properties. \textit{Journal of the American Statistical Association}, \textbf{96}, 1348--1360.

\bibitem[Steen-Adams(2005)]{steen05} Steen-Adams, M.M. (2005) Change on a Northern Wisconsin Landscape: Legacies of Human History. University of Wisconsin, Madison, Wisconsin, USA.

\end{thebibliography}


\newpage
%
% Tables
%
\begin{table}[!htbp]
\caption{Average number of correctly identified non-zero and zero regression coefficients when $\beta_1=5$ (weak large-scale structure) for uncentered and centered model, sample size $n=225$ or 900 and antoregression coefficient $\eta=0.3$ or 0.7.} % title of Table
\centering  % used for centering table
\begin{tabular}{rccccc} % centered columns
\hline\hline                        %inserts double horizontal lines
& $\{\beta_j\}$ & \multicolumn{2}{c}{Number of non-zero estimates}  & \multicolumn{2}{c}{Number of zero estimates}\\ [0.5ex]  % inserts table 
%heading
\multicolumn{1}{c}{Model} & $n$ & $\eta=0.3$ & $\eta=0.7$ & $\eta=0.3$ & $\eta=0.7$ \\
\hline                  % inserts single horizontal line

Uncentered &  255  & 2.77 & 2.69 &  6.12 & 6.14 \\
 &  900  & 3.00 & 3.00 & 6.81 & 6.88\\
Centered &  255  & 2.75 & 2.67& 6.21  & 6.17\\ 
  &  900 & 3.00 & 3.00 & 6.87 & 6.82\\ [1ex]      % [1ex] adds vertical space
\hline %inserts single line
\end{tabular}
\label{tab:selstrong} % is used to refer this table in the text
\end{table}

%
% Figures
%
\begin{figure}[ht]
\begin{center}
%\includegraphics[scale=0.6]{./Figures/MPLE225.pdf}
\end{center}
\caption{Box plot of the MPPLE $\widehat{\beta}_0$ (row 1), $\widehat{\beta}_1$ (row 2), $\widehat{\beta}_2$ (row 3) and $\widehat{\eta}$ (row 4) from the 100 simulations with sample size $n=225$. Column (a): uncentered model with $\beta_1=5$ (weak large-scale structure); (b): uncentered model with $\beta_1=1$ (strong large-scale structure); (c): centered model with $\beta_1=5$ (weak large-scale structure); (d): centered model with $\beta_1=1$ (strong large-scale structure). The true values are $\beta_0=1$, $\beta_1=1$ or 5, $\beta_2=1$, $\beta_3=1$, and $\eta=$ 0.3 or 0.7. The box plot of $\widehat{\beta}_3$ is similar to $\widehat{\beta}_2$ but omitted to save space.}
\label{fig:mple225}
\end{figure}
\end{document}

