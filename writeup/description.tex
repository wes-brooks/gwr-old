\documentclass[10pt]{amsart}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{natbib}

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{GW-SELECT}
\author{Wesley Brooks}
\date{}                                           % Activate to display a given date or no date

\begin{document}
\maketitle
%\section{}
%\subsection{}





\section{Introduction}
Varying-coefficient models are a technique in spatial statistics that can be useful when one suspects that the effect of some covariate is not constant across the domain of a model. One method if fitting a varying-coefficient model is Geographically Weighted Regression (GWR) \cite{Fotheringham:2002}. In GWR, the 

\section{Data}
Data should include the location of each observation in terms of an X (longitude) and Y (latitude) variable. If they correspond to actual longitude and latitude, then it is possible to call the functions with the option \verb!longlat=TRUE!, which will correct for the the Earth's curvature.\\

Otherwise, the data is pretty typical - a row for each observation and a column for each variable.\\

\section{GWR}
The basic operation of GWR is to build a regression model at each of a set of pre-specified locations. At each model location, all of the observations in the data set are weighted based on their distance from the model location (the weights are uniquely specified by the combination of a kernel function and a bandwidth). The weighted observations are then used to build a regression model that is only meaningful at that location. The regression model can be quite generic - for gaussian data something like \verb!R!'s \verb!lm! function is used, and for the binomial case, something like the \verb!glm! function is used. Prior weights can be specified in case over-dispersion (or heteroskedasticity) is expected. This came into play with the poverty data: each county's entry was weighted by its population.\\

\subsection{Kernels}
At this time there are two kernel functions working: the bisquare kernel:
\[
\text{W}(\text{dist, bw}) = (1-(\frac{\text{dist}}{\text{bw}})^2)^2
\]

...And the gaussian kernel:
\[
\text{W}(\text{dist, bw}) = \phi(\frac{\text{dist}}{\text{bw}})
\]


\subsection{Bandwidth selection}
The bandwidth is selected by minimizing the sum of absolute cross-validation (CV) errors from the model-fitting. Each of the unique observation locations is used as a model location, and the observations from that point are reserved as the test set. The model is built over the other data and used to predict the test set. The sum of the absolute errors from this prediction step are added to the total. The \verb!optimize! function in R uses a golden section search to find the minimum of the total absolute CV error.\\

\subsection{Gaussian case (linear model)}
test

\subsection{Generalized linear model}
test


\section{Variable selection}
Variable selection is done with the Adaptive LASSO.

The \verb!R! function \verb!lars! is used to fit a LASSO regression model to gaussian data; \verb!glmnet! is used to fit the model for binomial data. The function \verb!lars! allows the one to specify how the LASSO penalty is specified: the choices are to specify the penalty itself (\verb!mode=lambda!), the fraction of the total LASSO path (\verb!mode=fraction!), or the number of steps on the least-angle regression (LAR) path (\verb!mode=step!). I've always used \verb!mode=step'! for gaussian models. The only choice for a \verb!glmnet! model is \verb!mode=lambda! so that's what I use. Also, since \verb!lars! doesn't allow the user to specify weights, the first step in making each \verb!gwlars! model is to multiply the design matrix and the vector of observed outputs by the diagonal matrix of the square roots of the geographical weights. In the binomial case, the \verb!glmnet! function allows one to specify weights, so that is how the geographic weights are incorporated. The matrix multiplication in the gaussian case happens before the centering and scaling for the adaptive LASSO, discussed below.\\

When each (location-specific) model is built, each column of the design matrix is centered and scaled to have unit norm. Then the basic regression step (\verb!lm! or \verb!glm!) is used (with the scaled-to-unit-norm design matrix) to get the adaptive weights (the adaptive weight for each predictor variable is its coefficient in the basic model); each column is multiplied by its adaptive weight. This centered and adaptively-scaled design matrix is fed into the \verb!lars! or \verb!glmnet! function. These models also require the user to choose a tuning parameter. Here, the tuning parameter is chosen in the cross-validation step: the tuning parameter at each model location is set to the choice that minimizes the total absolute cross-validation error at that location (the ``total" CV error refers to the possibility that there are multiple observations at that location).\\

Remember, the tuning parameters are different between the gaussian and binomial cases: in the gaussian case, the tuning parameter is the number of steps along the LAR path, which ranges from zero to the number of predictor variables. In the binomial case, the tuning parameter is the LASSO penalty (i.e., $\lambda$ in the penalty term $\lambda \times \Sigma_{i=1}^p\beta_i$). I've been allowing $\lambda$ to range from zero to five in steps of 0.001.\\

\subsection{Gaussian case}


\subsection{Generalized linear model case}

\bibliographystyle{plain}
\bibliography{../references/gwr}

\end{document}  